### 使用 LogStash 同步Mysql 数据到 ElasticSearch   [参考](https://www.javazhiyin.com/47475.html)



##### 数据库脚本

数据库表结构中，需要有一个时间类型的字段作为增量更新的标识字段如 `lastupdatetime`，当该条数据更新时，必须同时更新该字段

```sql
CREATE TABLE user  (
  `id` int(11) NOT NULL,
  `name` varchar(50) NOT NULL,
  `age` int(11) NOT NULL,
  `createtime` datetime(0) NOT NULL,
  `lastupdatetime` datetime(0) NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) 
 
INSERT INTO `user` VALUES(1,"jack",18,Now(),Now())
INSERT INTO `user` VALUES(2,"William",18,Now(),Now())
 
SELECT * from `user`
```



##### LogStash 配置信息

```bash
mkdir /opt/logstashsync/
mkdir /opt/logstashsync/pipeline
vi /opt/logstashsync/pipeline/logstash.conf
```

```
input {
  jdbc {
    jdbc_driver_library => "/app/mysql-connector-java-8.0.18.jar"
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_connection_string => "jdbc:mysql://192.168.10.102:3306/synctest"
    jdbc_user => "root"
    jdbc_password => "123456"
    tracking_column => "unix_ts_in_secs"
    use_column_value => true
    schedule => "*/5 * * * * *" 
    statement => "SELECT *, UNIX_TIMESTAMP(lastupdatetime) AS unix_ts_in_secs FROM user WHERE (UNIX_TIMESTAMP(lastupdatetime) > :sql_last_value AND lastupdatetime < NOW()) ORDER BY lastupdatetime ASC"
  }
}
 
filter {
  mutate {
    copy => { "id" => "[@metadata][_id]"} 
    remove_field => ["id", "@version", "unix_ts_in_secs"]
  }
}
output {
   elasticsearch {
                 hosts => "192.168.10.102:9200"
                 index => "syncuser"
                 timeout => 300
                 document_id => "%{[@metadata][_id]}" 
                 }
}
```



配置说明：

- [ ] jdbc_driver_library：logstash的镜像中并不包含 jdbc connector，需要在官方网站中下载下来之后，在容器启动时映射到容器中，[下载](https://dev.mysql.com/downloads/connector/j/)
- [ ] tracking_column：用于跟踪 Logstash从MySQL读取的最后最后一条数据的 lastupdatetime 的值，并默认持久化到磁盘文件 .logstash_jdbc_last_run 中。该值用于在下一次循环同步时，同步的起始值，从而达到增量同步的作用，存储在 .logstash_jdbc_last_run 在 SQL 语句中可以以 :sql_last_value 访问
- [ ] schedule：设置多久循环同步一次，以cron语法指定，我们当前设置的是5秒一次循环。
- [ ] statement：执行同步的SQL语句。值得注意的是where条件中为什么要这么写，可以 [参考](https://www.elastic.co/blog/how-to-keep-elasticsearch-synchronized-with-a-relational-database-using-logstash) 文章中给定的解释
- [ ] 关于上述配置中的 [@metadata][_id]，在同步过程中，必须使用数据库数据id作为 ElasticSearch 中的文档 _id，这样当数据库中该条数据有修改时，ElasticSearch 中的文档才会相应的同步修改，否则会以一条新的数据插入 ElasticSearch，导致数据同步错误



##### 启动Logstash

```bahs
docker run -d \
-v /opt/logstashsync/config/logstash.yml:/usr/share/logstash/config/logstash.yml \
-v /opt/logstashsync/pipeline/logstash.conf:/usr/share/logstash/pipeline/logstash.conf \
-v /opt/logstashsync/mysql-connector-java-8.0.18.jar:/app/mysql-connector-java-8.0.18.jar \
--name=logstash \
logstash:6.7.1
```

