### 搭建说明

裸机搭建至少需要两台服务器，一个master节点，一个或多个work节点，其中master必须要安装的组件有docker/podman，kubectl，kubeadm，工作节点需安装docker/podman，kubelet，kube-proxy

```
Kubeadm：集群初始化工具

Kubectl：集群命令交互工具

Kubelet：管理pod和容器

Kube-proxy：网络代理，负责网络相关的工作
```





### 开始安装

```shell
# 每个节点分别设置对应主机名
hostnamectl set-hostname master
hostnamectl set-hostname node1
hostnamectl set-hostname node2

# 修改所有节点的 hosts
vim /etc/hosts
# ip换成自己的内网ip
# 172.16.32.2 node1
# 172.16.32.6 node2
# 172.16.0.4 master

# 找一台机器分别ping一下其他两台机器，看是否能ping通
ping master
ping node2


# 关闭所有节点 SELinux
setenforce 0
sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux

# 关闭所有节点swap分区
swapoff -a
sed -ri 's/.*swap.*/#&/' /etc/fstab 


# 将桥接的IPv4流量传递到iptables的链
cat > /etc/sysctl.d/k8s.conf << EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
net.ipv4.ip_forward=1
net.ipv4.tcp_tw_recycle=0
vm.swappiness=0
vm.overcommit_memory=1
vm.panic_on_oom=0
fs.inotify.max_user_instances=8192
fs.inotify.max_user_watches=1048576
fs.file-max=52706963
fs.nr_open=52706963
net.ipv6.conf.all.disable_ipv6=1
net.netfilter.nf_conntrack_max=2310720         
EOF
# 配置生效
sysctl --system

echo "1" > /proc/sys/net/ipv4/ip_forward
service network restart
reboot

# 确保所有节点防火墙已经关闭
systemctl stop firewalld
systemctl disable firewalld

```



添加安装源：

```shell
# 所有节点都需要安装
cat <<EOF > kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF


mv kubernetes.repo /etc/yum.repos.d/


# 添加 Docker 安装源
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
```



安装组件：

```shell
# 在所有节点执行一下命令，master节点可以不安装kubelet
yum install -y kubelet kubeadm kubectl docker-ce

# yum remove kubelet kubeadm kubectl docker-ce docker-ce-cli containerd.io

# 所有节点设置开机启动
systemctl enable kubelet
systemctl start kubelet
systemctl enable docker
systemctl start docker

```



修改所有节点的docker镜像源：

```shell
# kubernetes 官方推荐 docker 等使用 systemd 作为 cgroupdriver，否则 kubelet 启动不了
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "registry-mirrors": ["https://rwfl9tc3.mirror.aliyuncs.com"]
}
EOF

sudo systemctl daemon-reload
sudo systemctl restart docker
```





初始化集群：

```shell
# 在master节点上运行以下命令
kubeadm init --image-repository=registry.aliyuncs.com/google_containers

# kubeadm config images list
# kubectl veriosn
# kubeadm init --apiserver-advertise-address=124.221.114.170 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.23.4 --service-cidr=10.96.0.0/12　--pod-network-cidr=10.244.0.0/16

kubeadm init \
--image-repository registry.aliyuncs.com/google_containers \
--kubernetes-version v1.23.5 \
--service-cidr=10.96.0.0/12 \
--pod-network-cidr=10.244.0.0/16 \
--v=5


# 初始化完成后会打印以下命令，并将该命令复制到worker节点执行，将worker加入到集群中
# kubeadm join 10.0.16.3:6443 --token rgqd2u.6i5ixnetl3dnr3ri --discovery-token-ca-cert-hash sha256:6af34386ed9c95de11b1b27637b0e4de330fb7444fbacfe57e165fe50457c3e5 

# 若忘记复制kubeadm join 命令，可以使用以下命令重新生成
# kubeadm token create --print-join-command


# 在master节点上复制授权文件，以便 kubectl 可以有权限访问集群
# 如果其他节点需要访问集群，需要从主节点复制这个文件过去其他节点
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config


# 在master上执行一下命令，查看集群信息
kubectl get node

# 使用 kubectl get node 查看集群信息时，发现节点状态都是NotReady，在master节点上执行以下命令，安装网络插件即可
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

```



至此，k8s集群已安装完成



```shell
# 在主节点 master
# sudo iptables -t nat -A OUTPUT -d <主节点公网IP> -j DNAT --to-destination <主节点私有IP>
sudo iptables -t nat -A OUTPUT -d 124.221.114.170 -j DNAT --to-destination 10.0.16.3

# 在 node 节点上
# sudo iptables -t nat -A OUTPUT -d <主节点私有IP> -j DNAT --to-destination <主节点公网IP>
sudo iptables -t nat -A OUTPUT -d 10.0.16.3 -j DNAT --to-destination 124.221.114.170

kubeadm config images list
kubeadm token create --print-join-command

kubeadm join 124.221.114.170:6443 --token 32nfh3.p1rx2d6qxqtb4s7b --discovery-token-ca-cert-hash sha256:513614df5b6d31e3f27be5d3c242f10bc0c6c3665673f5a5f6556c78c84096b6 --v=5
```







### 应用部署



#### Pod

运行一个名为testapp的pod：

```shell
# --image 指定镜像
kubectl run testapp --image=nginx

# 查看pod
kubectl get pod
```



或者使用yaml文件创建pod：

```yml
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  # 定义容器，可以多个
  containers:
    - name: test-k8s # 容器名字
      image: ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1 # 镜像
```



使用命令运行：

```shell
kubectl apply -f pod.yaml
```





#### Deployment

一般使用deployment去管理pod

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  # 部署名字
  name: test-k8s
spec:
  # pod副本数量
  replicas: 2
  # 用来查找关联的 Pod，所有标签都匹配才行
  selector:
    matchLabels:
      # key：value 自定义
      app: test-k8s
  # 定义 Pod 相关数据
  template:
    metadata:
      labels:
        # 这里要和上面自定义的key：value一致，否则关联不上
        app: test-k8s
    spec:
      # 定义容器，可以多个
      containers:
      - name: test-k8s # 容器名字
        image: ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v1 # 镜像
```



 

```shell
# 运行deployment
kubectl apply -f deployment.yaml

# 查看deployment
kubectl get deployment

# 查看pod，通过deployment创建的pod，名字后面会加上随机的字符串
kubectl get pod

# -o wide 可以查看pod的详细信息，包括ip，节点等
kubectl get pod -o wide

# 查看某个pod的详细数据
kubectl describe pod pod-name

# 查看日志
kubectl logs -f pod-name

# 进入 Pod 容器终端， -c container-name 可以指定进入哪个容器
kubectl exec -it pod-name -- bash
```



其他命令

```shell
# 伸缩扩展副本
kubectl scale deployment test-k8s --replicas=5

# 把集群内端口映射到节点
kubectl port-forward pod-name 8090:8080

# 查看历史
kubectl rollout history deployment test-k8s

# 回到上个版本
kubectl rollout undo deployment test-k8s

# 回到指定版本
kubectl rollout undo deployment test-k8s --to-revision=2

# 删除部署
kubectl delete deployment test-k8s

```



```shell
# 查看全部
kubectl get all

# 重新部署
kubectl rollout restart deployment test-k8s

# 命令修改镜像，--record 表示把这个命令记录到操作历史中
kubectl set image deployment test-k8s test-k8s=ccr.ccs.tencentyun.com/k8s-tutorial/test-k8s:v2-with-error --record

# 暂停运行，暂停后，对 deployment 的修改不会立刻生效，恢复后才应用设置
kubectl rollout pause deployment test-k8s

# 恢复
kubectl rollout resume deployment test-k8s

# 输出到文件
kubectl get deployment test-k8s -o yaml >> app2.yaml

# 删除全部资源
kubectl delete all --all
```





#### Service



























