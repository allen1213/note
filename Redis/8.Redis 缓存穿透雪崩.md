

大量的请求直接落在数据库上，而没有经过redis缓存



### Redis 缓存穿透



用户要请求一个数据，发现redis中没有，查询数据库也没有，当用户发送大量请求时，缓存都没有命中，都去请求了持久层数据库，就出现了缓存穿透



解决方案：

- [ ] 布隆过滤器

  将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力

  

- [ ] 缓存空对象，无论是否命中都保存一个值，并设置过期时间，但这种方法会存在两个问题：

  如果空值能够被缓存起来，缓存需要更多的空间存储更多的键，因为这当中可能会有很多的空值的键

  即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间数据不一致，比如请求时没有，但在key还没过期时新增请求的数据，导致请求到redis中的空值而查不到数据






#### 布隆过滤器

布隆过滤器是一种基于概率的数据结构，主要用来判断某个元素是否在集合内，具有运行速度快，占用内存小的优点，但是有一定的误判，他只能判断一个元素一定不在集合内，或者可能在集合内



布隆过滤器其实就是一个很大的二进制数组，数组的值只有1和0，当存放一个值时，不是存具体值，而是经过m个哈希函数，得到m个下标值并将这m个数组值改成1，布隆过滤器不提供删除方法



布隆过滤器存在误判的情况，因为布隆过滤器不存元素值，所以存在误判率，比如数组种存在x，y，z三个值对应的数组下标为 1，3，5，7，9，当查询a时，经过的hash函数得到的下标为1，7，但是数组并没有a这个值



布隆过滤器越大或哈希函数越多，误判率就越小，上面的例子也说明了不提供删除方法是因为若删除a，可能就会对x y z三个值有影响



对于要手写一个布隆过滤器，要有这三个部分：若干哈希函数，存值，判断值是否在数组中



但是也可以使用的谷歌的 Google Guava

```xml
<dependency>
    <groupId>com.google.guava</groupId>
    <artifactId>guava</artifactId>
    <version>27.0.1-jre</version>
</dependency>
```



实际项目中的具体操作代码，一般都会启动一个定时任务将值放到布隆过滤器中

```java
public static void MyBloomFilterSysConfig {

     @Autowired
     OrderMapper orderMapper

    // 1.创建布隆过滤器  第二个参数为预期数据量10000000，第三个参数为错误率0.00001
    BloomFilter<CharSequence> bloomFilter =  BloomFilter.create(Funnels.stringFunnel(Charset.forName("utf-8")),10000000, 0.00001);
    // 2.获取所有的订单，并将订单的id放进布隆过滤器里面
    List<Order> orderList = orderMapper.findAll()
    for (Order order;orderList ) {
        Long id = order.getId();
        bloomFilter.put("" + id);
    }
}
```



使用布隆过滤器，判断元素是否存在

```java
// 判断订单id是否在布隆过滤器中存在
bloomFilter.mightContain("" + id)
```



布隆过滤器的缺点就是要维持容器中的数据，因为订单数据变化频繁，实时的要更新布隆过滤器中的数据为最新









### Redis 缓存击穿



缓存击穿是指一个key在数据库中，这个key一般是热点数据，但在redis中过期，此时若有大量并发请求过来，可能会瞬间把数据库压垮



当用户出现大并发访问的时候，在查询缓存的时候和查询数据库的过程加锁，只能第一个进来的请求进行执行，当第一个请求把该数据放进缓存中，接下来的访问就会直接集中缓存，防止缓存击穿



解决方案：

- [ ] 比较普遍的一种方法是，根据key获取value值为空时，锁上，从数据库中`load`数据后再释放锁，若其它线程获取锁失败，则等待一段时间后重试，分布式环境中要使用分布式锁，单机的话用普通的锁`synchronized`、`Lock`就够了

  

  单机版：

  ```java
  // 获取库存数量
  public String getProduceNum(String key) {
      try {
          synchronized (this) {   //加锁
              // 缓存中取数据，并存入缓存中
              int num= Integer.parseInt(redisTemplate.opsForValue().get(key));
  
              if (num> 0) {
                  System.out.println("剩余的库存为num：" + num);
              } else {
                  System.out.println("库存为0");
              }
          }
      } catch (NumberFormatException e) {
          e.printStackTrace();
      } finally {
      }
      return "OK";
  }
  ```

  

  分布式实现方式：

  ```java
  public String getProduceNum(String key) {
      // 获取分布式锁
      RLock lock = redissonClient.getLock(key);
      try {
          // 获取库存数
          int num= Integer.parseInt(redisTemplate.opsForValue().get(key));  
          // 上锁           
          lock.lock();
          if (num> 0) {
              System.out.println("剩余库存为num：" + num);
          } else {
              System.out.println("库存已经为0");
          }
      } catch (NumberFormatException e) {
          e.printStackTrace();
      } finally {
          //解锁
          lock.unlock();
      }
      return "OK";
  }
  ```

  

- [ ] 使用互斥锁 mutex key

  在缓存失效的时候不是立即去请求数据库，而是先使用缓存工具的某些带成功操作返回值的操作，比如Redis的SETNX或者Memcache的ADD去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存，否则就重试整个get缓存的方法

  SETNX「SET if Not eXists」：

  ```java
  public String get(key) {
      
      String value = redis.get(key);
      //代表缓存值过期
      if (value == null) { 
          //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db
          if (redis.setnx(key_mutex, 1, 3 * 60) == 1) { 
              //查数据库
              value = db.get(key);
              redis.set(key, value, expire_secs);
              redis.del(key_mutex);
          } else { 
              //这个时候代表其他线程已经load db并回设到缓存了，重试获取缓存值
              sleep(50);
              get(key);  //重试
          }
      } else {
          return value; 
      }
   }
  ```

  





### Redis 雪崩



缓存雪崩是指，redis缓存出现错误不能正常工作或者大面积的key在同一时间过期，所有请求都到数据库，造成数据库挂掉的情况，造成redis 缓存雪崩有两个原因：redis 宕机，大部分数据失效



解决方案：

- [ ] redis集群高可用

- [ ] 限流降级

  在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量，比如对某个key只允许一个线程查询数据和写缓存，其他线程等待

- [ ] 数据预热

  先把可能的数据访问一遍，这样部分可能大量访问的数据就会加载到缓存中，在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀